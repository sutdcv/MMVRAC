# [2024 ICME Grand Challenge] Multi-Modal Video Reasoning and Analyzing Competition (MMVRAC) 

Given the enormous amount of multi-modal multi-media information that we encounter in our daily lives (including visuals, sounds, texts, and interactions with their surroundings), we humans process such information with great ease â€“ we understand and analyze, think rationally and reason logically, and then predict and make sound judgments and informed decision based on various modalities of information available. 

For machines to assist us in holistic understanding and analysis of events, or even to achieve such sophistication of human intelligence (e.g., Artificial General Intelligence (AGI) or even Artificial Super Intelligence (ASI)), they need to process visual information from real-world videos, alongside complementary audio and textual data, about the events, scenes, objects, their attributes, actions, and interactions.

Hence, we hope to further advance such developments in multi-modal video reasoning and analyzing for different scenarios and real-world applications through this Grand Challenge using various challenging multi-modal datasets with different types of computer vision tasks (i.e., video grounding, spatiotemporal event grounding, video question answering, sound source localization, person reidentification, attribute recognition, pose estimation, skeleton-based action recognition, spatiotemporal action localization, behavioral graph analysis, animal pose estimation and action recognition) and multiple types of annotations (i.e., audio, visual, text). This Grand Challenge will culminate in the 2nd Workshop on Multi-Modal Video Reasoning and Analyzing Competition (MMVRAC). 

## ORGANIZERS 
* Jun Liu, Singapore University of Technology and Design, Singapore
* Bingquan Shen, DSO National Laboratories and National University of Singapore
* Ping Hu, Boston University
* Kian Eng Ong, Singapore University of Technology and Design, Singapore
* Haoxuan Qu, Singapore University of Technology and Design, Singapore
* Duo Peng, Singapore University of Technology and Design, Singapore 
* Xun Long Ng, Singapore University of Technology and Design, Singapore

## CONTACT 
Please email kianeng_ong [AT] mymail.sutd.edu.sg for any enquiry.

## PAST ITERATION OF CHALLENGE
Information and results of the previous iteration of the Challenge (i.e., 1st Multi-modal Video Reasoning and Analyzing Competition at 2021 ICCV) can be found here: https://sutdcv.github.io/multi-modal-video-reasoning
